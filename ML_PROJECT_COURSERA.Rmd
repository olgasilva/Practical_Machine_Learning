
---
title: "ML project"
author: "OS"
date: "October 7, 2018"
output:
  html_document:
    keep_md: true
---
#Coursera - Practical Machine Learning Project

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, my goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, to predict the manner in which they did the exercise

##Set up the libraries
```{r libraries, echo=TRUE}
library(caret)
library(randomForest)
library(rattle)
library(e1071) 
library(rpart)
library(gbm)

```

##Load the data
```{r data, echo=TRUE}
train_data<-read.csv("pml-training.csv", header = TRUE)
test_data<-read.csv("pml-testing.csv", header = TRUE)
```
create a new partition
```{r partition, echo=TRUE}
to_part  <- createDataPartition(train_data$classe, p=0.7, list=FALSE)
train2_data <- train_data[to_part, ]
test2_data <- train_data[-to_part, ]
```

##Explore and clean the data

There are columns that are mostly empty, I will remove them for the data. I will also remove identification only variables (columns 1 to 7)

```{r remove, echo=TRUE}
data_remove <- sapply(train2_data, function(x) mean(is.na(x))) > 0.90
train2_data <- train2_data[, data_remove==FALSE]
test2_data  <- test2_data[, data_remove==FALSE]
zero <- nearZeroVar(train2_data)
train2_data <- train2_data[, -zero]
test2_data  <- test2_data[, -zero]
train2_data <- train2_data[, -(1:5)]
test2_data <- test2_data[, -(1:5)]
```

##Prediction

###Random forest

```{r random_forest, echo=TRUE}
set.seed(12345)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modFitRandForest <- train(classe ~ ., data=train2_data, method="rf",
                          trControl=controlRF)
modFitRandForest$finalModel
```

We will use it with the test dataset

```{r test_prediction, echo=TRUE}
predictRF <- predict(modFitRandForest, newdata=test2_data)
confMatRF <- confusionMatrix(predictRF, test2_data$classe)
confMatRF
```

###Decision Trees
```{r trees, echo=TRUE}
set.seed(12345)
modFitDT <- rpart(classe ~ ., data=train2_data, method="class")
fancyRpartPlot(modFitDT)
```

We will use it with the test dataset

```{r tree_prediction, echo=TRUE}
predictDT <- predict(modFitDT, newdata=test2_data, type="class")
confMatDT <- confusionMatrix(predictDT, test2_data$classe)
confMatDT
```

##Generalized Boosted Model
This will be the last method to test
```{r GBM, echo=TRUE}
set.seed(12345)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGBM  <- train(classe ~ ., data=train2_data, method = "gbm",
                    trControl = controlGBM, verbose = FALSE)
modFitGBM$finalModel
```

Now it is time to predict

```{r GBM_prediction, echo=TRUE}
predictGBM <- predict(modFitGBM, newdata=test2_data)
confMatGBM <- confusionMatrix(predictGBM, test2_data$classe)
confMatGBM
```

##Select the model

Random Forests gave an Accuracy of  99,66%, which was more accurate that what I got from the Decision Trees (74,72%) or GBM (98,56%)

```{r final_model, echo=TRUE}
predictTEST <- predict(modFitRandForest, newdata=test_data)
predictTEST
```

